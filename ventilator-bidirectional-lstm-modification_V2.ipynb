{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes comparing V1:  \n",
    "\n",
    "* Adding new features:  \n",
    "\n",
    "    df['u_in_first'] = df.groupby(['breath_id'])['u_in'].transform('first')  \n",
    "    df['u_in_last'] = df.groupby(['breath_id'])['u_in'].transform('last')\n",
    "    \n",
    "    df.loc[train['time_step'] == 0, 'u_in_diff'] = 0  \n",
    "    df.loc[train['time_step'] == 0, 'u_out_diff'] = 0  \n",
    "    \n",
    "* Using Rescaling laying for discrete output  \n",
    "\n",
    "* Ensemble folds with median  \n",
    "   Ensembble folds with median and round predictions\n",
    "\n",
    "Results:  \n",
    "\n",
    "   * Median: 0.150  \n",
    "   * Median and round predictions: 0.159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "3e5a0bd1-3e22-4b2c-a565-68985e55f95e",
    "_uuid": "e331dbcc-0346-4019-9ff6-b890154a878b",
    "execution": {
     "iopub.execute_input": "2021-10-09T09:51:08.913772Z",
     "iopub.status.busy": "2021-10-09T09:51:08.913371Z",
     "iopub.status.idle": "2021-10-09T09:51:16.143515Z",
     "shell.execute_reply": "2021-10-09T09:51:16.142657Z",
     "shell.execute_reply.started": "2021-10-09T09:51:08.913651Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "89eb257e-0ed2-4f8b-94d6-462a5e995eb1",
    "_uuid": "ca71d87d-6594-4f31-906d-0b53cd4c1374",
    "execution": {
     "iopub.execute_input": "2021-10-09T09:51:16.145381Z",
     "iopub.status.busy": "2021-10-09T09:51:16.145128Z",
     "iopub.status.idle": "2021-10-09T09:51:32.325238Z",
     "shell.execute_reply": "2021-10-09T09:51:32.324422Z",
     "shell.execute_reply.started": "2021-10-09T09:51:16.145352Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "if DEBUG:\n",
    "    train = train[:80*1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:51:32.326985Z",
     "iopub.status.busy": "2021-10-09T09:51:32.326743Z",
     "iopub.status.idle": "2021-10-09T09:51:32.406559Z",
     "shell.execute_reply": "2021-10-09T09:51:32.405765Z",
     "shell.execute_reply.started": "2021-10-09T09:51:32.326957Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pressure = np.sort(train['pressure'].unique())\n",
    "pressure_min =  all_pressure[0].item()\n",
    "pressure_max = all_pressure[-1].item()\n",
    "pressure_step = (all_pressure[1] - all_pressure[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:51:32.409164Z",
     "iopub.status.busy": "2021-10-09T09:51:32.408842Z",
     "iopub.status.idle": "2021-10-09T09:51:32.423007Z",
     "shell.execute_reply": "2021-10-09T09:51:32.422134Z",
     "shell.execute_reply.started": "2021-10-09T09:51:32.409124Z"
    }
   },
   "outputs": [],
   "source": [
    "display(pressure_min)\n",
    "display(pressure_max)\n",
    "display(pressure_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From [Ventilator: Feature engineering](https://www.kaggle.com/mistag/ventilator-feature-engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "13a36b46-7067-4b29-aad3-7e3b15e8415b",
    "_uuid": "dc41dbf2-f199-4b9d-bbd9-bf6084162b47",
    "execution": {
     "iopub.execute_input": "2021-10-09T09:51:32.424811Z",
     "iopub.status.busy": "2021-10-09T09:51:32.424536Z",
     "iopub.status.idle": "2021-10-09T09:52:29.487099Z",
     "shell.execute_reply": "2021-10-09T09:52:29.486367Z",
     "shell.execute_reply.started": "2021-10-09T09:51:32.424777Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "def add_features(df):\n",
    "    #time_step*u_in\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    \n",
    "    #sum of u_in\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    \n",
    "    #shift +1 -1 +3 -3\n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "         \n",
    "    df['u_in_first'] = df.groupby(['breath_id'])['u_in'].transform('first')\n",
    "    df['u_in_last'] = df.groupby(['breath_id'])['u_in'].transform('last')\n",
    "    \n",
    "    # max value of u_in and u_out for each breath\n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "   \n",
    "    # difference between consequitive values\n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    \n",
    "    df.loc[train['time_step'] == 0, 'u_in_diff'] = 0\n",
    "    df.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n",
    "    \n",
    "    # difference between the current value of u_in and the max value within the breath\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    # difference between the current value of u_in and the mean value within the breath\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    # difference between consequitive values\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    \n",
    "    #u_in*u_out\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    \n",
    "    #time_step*u_out\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    #one hot encoding\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:29.488987Z",
     "iopub.status.busy": "2021-10-09T09:52:29.488152Z",
     "iopub.status.idle": "2021-10-09T09:52:29.494993Z",
     "shell.execute_reply": "2021-10-09T09:52:29.494126Z",
     "shell.execute_reply.started": "2021-10-09T09:52:29.488927Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:29.496518Z",
     "iopub.status.busy": "2021-10-09T09:52:29.496171Z",
     "iopub.status.idle": "2021-10-09T09:52:30.535640Z",
     "shell.execute_reply": "2021-10-09T09:52:30.534553Z",
     "shell.execute_reply.started": "2021-10-09T09:52:29.496475Z"
    }
   },
   "outputs": [],
   "source": [
    "check_train_nan = train.isnull().sum().sum()\n",
    "check_test_nan = test.isnull().sum().sum()\n",
    "\n",
    "print(check_train_nan)\n",
    "print(check_test_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:30.537481Z",
     "iopub.status.busy": "2021-10-09T09:52:30.536952Z",
     "iopub.status.idle": "2021-10-09T09:52:30.566372Z",
     "shell.execute_reply": "2021-10-09T09:52:30.565564Z",
     "shell.execute_reply.started": "2021-10-09T09:52:30.537435Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "01328860-fa2a-421c-9e5f-ea0048246f98",
    "_uuid": "346bf2c0-96d2-4da5-8837-c0f820294a85",
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:30.567920Z",
     "iopub.status.busy": "2021-10-09T09:52:30.567523Z",
     "iopub.status.idle": "2021-10-09T09:52:31.789590Z",
     "shell.execute_reply": "2021-10-09T09:52:31.788897Z",
     "shell.execute_reply.started": "2021-10-09T09:52:30.567889Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
    "test = test.drop(['id', 'breath_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:31.792661Z",
     "iopub.status.busy": "2021-10-09T09:52:31.791779Z",
     "iopub.status.idle": "2021-10-09T09:52:42.692853Z",
     "shell.execute_reply": "2021-10-09T09:52:42.691870Z",
     "shell.execute_reply.started": "2021-10-09T09:52:31.792621Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalise the dataset\n",
    "RS = RobustScaler()\n",
    "train = RS.fit_transform(train)\n",
    "test = RS.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:42.694345Z",
     "iopub.status.busy": "2021-10-09T09:52:42.694073Z",
     "iopub.status.idle": "2021-10-09T09:52:42.699411Z",
     "shell.execute_reply": "2021-10-09T09:52:42.698473Z",
     "shell.execute_reply.started": "2021-10-09T09:52:42.694315Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reshape group to 80 timesteps for each breath ID\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From [Rescaling layer for discrete output in TensorFlow](https://www.kaggle.com/lucamassaron/rescaling-layer-for-discrete-output-in-tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please notice the custom rounding round_with_gradients function since tf.round has no gradients and it won't be differentiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:42.700799Z",
     "iopub.status.busy": "2021-10-09T09:52:42.700550Z",
     "iopub.status.idle": "2021-10-09T09:52:42.713186Z",
     "shell.execute_reply": "2021-10-09T09:52:42.712272Z",
     "shell.execute_reply.started": "2021-10-09T09:52:42.700768Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def round_with_gradients(x):\n",
    "    def grad(dy):\n",
    "        return dy\n",
    "    return tf.round(x), grad\n",
    "\n",
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "        self.min = tf.constant(pressure_min, dtype=np.float32)\n",
    "        self.max = tf.constant(pressure_max, dtype=np.float32)\n",
    "        self.step = tf.constant(pressure_step, dtype=np.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        steps = tf.math.divide(tf.math.add(inputs, -self.min), self.step)\n",
    "        int_steps = round_with_gradients(steps)\n",
    "        rescaled_steps = tf.math.add(tf.math.multiply(int_steps, self.step), self.min)\n",
    "        clipped = tf.clip_by_value(rescaled_steps, self.min, self.max)\n",
    "        return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T09:52:42.715234Z",
     "iopub.status.busy": "2021-10-09T09:52:42.714928Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCH = 300\n",
    "BATCH_SIZE = 1024\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "#GPU init\n",
    "#gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "#with gpu_strategy.scope():\n",
    "with tpu_strategy.scope():\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n",
    "    test_preds = []\n",
    "    \n",
    "    def BiLSTM_model():\n",
    "        inputs = keras.layers.Input(shape=train.shape[-2:])\n",
    "        x = inputs\n",
    "        #bidirectional LSTM 1024->512->256->128\n",
    "        x = keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True))(x)\n",
    "        x = keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True))(x)\n",
    "        x = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "        x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "        x = keras.layers.Dense(128, activation='selu')(x)\n",
    "        # keras.layers.Dropout(0.1)\n",
    "        outputs = keras.layers.Dense(1)(x)\n",
    "        outputs = ScaleLayer()(outputs)\n",
    "        \n",
    "        model  = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "\n",
    "        model = BiLSTM_model()\n",
    "        \n",
    "        scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n",
    "        lr = LearningRateScheduler(scheduler, verbose=1)\n",
    "        \n",
    "        #lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "        #lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    \n",
    "        checkpoint_filepath = f\"folds{fold}.hdf5\"\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "            save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "            options=None\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
    "        #model.save(f'Fold{fold+1} RNN Weights')\n",
    "        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median method from [Chris Deotte](https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN\n",
    "#取中位数\n",
    "submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n",
    "submission.to_csv('submission_median.csv', index=False)\n",
    "\n",
    "\n",
    "# ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\n",
    "submission[\"pressure\"] =\\\n",
    "    np.round( (submission.pressure - pressure_min)/pressure_step ) * pressure_step + pressure_min\n",
    "submission.pressure = np.clip(submission.pressure, pressure_min, pressure_max)\n",
    "submission.to_csv('submission_median_round.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
